### Use Case

- Service crawls a list of urls. Generates reverse index of words to pages containing the search terms.
- User inputs a search term and sees a list of relevant pages with titles and snippets the crawler generated.

### URL Frontier / Queue

Based on the implementation in the Mercator web crawler.

- Front queues - This set of queues implement prioritization. Each queue has a priority label. 
The higher the priority, the sooner the URL popped from the queue.
- Back queues - This set of queues implement politeness. Each queue contains URLs from only one host.
- Min - Heap - There is one entry for each back queue. Each entry contains the server/host address and the earliest time 
when the request can be made.
- Caller threads - When we extract an URL from the back queue this thread group fetches the URLs and assigns URLs to the back queues.

### Bottleneck of DNS Resolution

- Caching the IP Addresses
- Fetching the IP Addresses asynchronously - Have separate worker threads that send requests to the DNS servers. 

### Distributed URL frontier

- Partition nodes by hash range of URL
- Partition nodes by hash range of Hosts. If there's a separate domain-name resolution service.

### Storage

- Store webpage content in an object store
- Store Link-to-link relationshiop in a graph database

### Deduplication

- Content deduplication. MD5 / SHA1 hash algorithm to generate document fingerprint.
- URL deduplication. Bloom filter.

### Inverted Index Service

- Asynchronous jobs to generate inverted index.

### Reference 

1. https://leetcode.com/discuss/interview-question/system-design/2950256/High-Level-Design-of-a-Web-Crawler
2. https://github.com/donnemartin/system-design-primer/blob/master/solutions/system_design/web_crawler/README.md
3. https://www.youtube.com/watch?v=OmyHt0JM7HM
4. https://www.youtube.com/watch?v=MdWvMX4J-Vc